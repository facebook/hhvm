/*
   +----------------------------------------------------------------------+
   | HipHop for PHP                                                       |
   +----------------------------------------------------------------------+
   | Copyright (c) 2010-present Facebook, Inc. (http://www.facebook.com)  |
   +----------------------------------------------------------------------+
   | This source file is subject to version 3.01 of the PHP license,      |
   | that is bundled with this package in the file LICENSE, and is        |
   | available through the world-wide-web at the following url:           |
   | http://www.php.net/license/3_01.txt                                  |
   | If you did not receive a copy of the PHP license and are unable to   |
   | obtain it through the world-wide-web, please send a note to          |
   | license@php.net so we can mail you a copy immediately.               |
   +----------------------------------------------------------------------+
*/

/*
IR function inliner

Inlining functions at the IR level can be complex, particularly when dealing
with async callees. All inlined regions are setup the same way, though later
optimization passes may attempt to elide elements of this inititalization,
particularly the DefinlineFP. Below is an annotated version of this setup.

  StStk ...  # Stores initiated for parameters as if this was an ordinary call.

  #
  # This is where this module starts to emit instructions, the stores and spills
  # are generated by passing arguments and emitting FCall* instructions, prior
  # to having made a decision about inlining.
  #

  LdStk ...     # The inliner first loads all of the arguments off of the stack,
                # effectively popping them. These loads and the preceding
                # stores are generally elided by load and store elimination.

  DefCalleeFP # Sets up memory effects for the inlined frame and returns a new
                # fp that can be used for stores into the frame.

  StLoc ...     # At this point the arguments are stored back to the frame
                # locations for their corresponding locals in the callee. N.B.
                # that in memory these are the same addresses as the stack
                # locations above.

Once the inlined function returns, the callee must be torn down and the return
value moved into the caller. The sequence for this is annotated below.

  tx := LdLoc ... # Locals are decref'ed inline. A GenericRetDecRefs is never
  DecRef tx       # emitted for inlined regions, in the hopes that IncRefs from
  ...             # pushing arguments will cancel DecRefs from the return.

  ty := LdFrameThis     # The context is DecRef'ed
  DecRef ty

  LeaveInlineFrame # This instruction marks the end of the inlined region,
                   # beyond this point the frame should no longer considered to
                   # be live. The locals and context have been explicitly
                   # decrefed.

Side exits from inlined code must publish the frames using the InlineCall
instruction.

  InlineCall    # This instruction links the new frame to the old frame via the
                # m_sfp field and loads the new frame into rvmfp(). It can be
                # thought of as doing the work of a Call.

  <exit>        # An instruction with ExitEffects, such as ReqBindJmp or
                # EndCatch.

We also support inlining of async functions. Returning from an inlined region
is handled differently depending on whether or not the caller entered the
region using FCall with an async eager offset. If the offset was specified,
the execution continues at that offset. Otherwise the result is wrapped in
a StaticWaitHandle and the execution continues at the next opcode.

Async functions may also exit by suspending. The suspend block is annotated
below:

tCallee := DefLabel   # The callee region may suspend from multiple locations,
                      # but after constructing the waithandle they must all
                      # branch to a common suspend block which will continue
                      # execution of the caller at the opcode following FCall,
                      # usually an Await.

LeaveInlineFrame      # The return sequence looks the same as a regular call but
                      # rather than killing the frame it has been teleported to
                      # the heap.

If a FCall with an async eager offset was followed by an Await, this HHIR
sequence follows the InlineSuspend:

tState := LdWhState   # Check the state of the waithandle representing the
JmpZero succeeded     # suspended callee. It may have finished in meanwhile due
EqInt 1               # to ability of surprise hooks to execute arbitrary Hack
JmpNZero failed       # code, so side-exit if that's the case.

tCaller := CreateAFWH # An AFWH is constructed for the caller, as Await must
                      # suspend if waithandle is not finished.

CheckSurpriseFlags    # The caller suspend hook is entered if requested.

RetCtrl               # Control is returned, suspending the caller. In the case
                      # of nested inlined FCall instructions this return would
                      # simply be a branch to the suspend block for the next
                      # most nested callee.

Calls to async functions without async eager offset use an analogous suspend
block which side-exits rather than continuing at the next opcode. This is done
so that the fast path through the callee will return only StaticWaitHandles
which may be elided by the DCE and simplifier passes.

Inlined regions maintain the following invariants, which later optimization
passes may depend on (most notably DCE and partial-DCE):

  - Every callee region must contain a single DefCalleeFP
  - DefCalleeFP must dominate every instruction within the callee.
  - Excluding side-exits and early returns, LeaveInlineFrame must post-dominate
    every instruction in the callee.
  - The callee must contain a return or await.

When a callee contains awaits, these will be implemented as either an await of
the nested callee (in the case of FCall) or a return from the callee and
side-exit from the caller, unless the callee does not contain a return (e.g.
the caller was profiled as always suspending), in which case the callee will
return the waithandle to the caller rather than side-exiting in the case of a
FCall without async eager offset.

Below is an unmaintainable diagram of a pair of an async function inlined into a
pair of callers with and without (*) async eager offset respectively,


Outer:                                 | Inner:
  ...                                  |   ...
  FCall "Inner" aeo1 or FCall "Inner"  |   FCall "Other" aeo2
  Await                                |   Await
 aeo1:                                 |  aeo2:
  ...                                  |   ...

          ...
           |
           v
+-------------------+
| ...               |
| DefCalleeFP     |
| StLoc             |
| ...               |
+-------------------+
           |
           v
+-------------------+
| ...               |
| tx = Call "Other" |
| ty = LdTVAux tx   |
| JmpNZero ty       | -> +---------------------+
+-------------------+    | ta = CreateAWFH tx  |
           |             | SuspendHook         |
           v             | StStk ta            |
+-------------------+    | Jmp suspendTarget   |--- or (*) ----+
| StStk tx          |    +---------------------+               |
| ... // aeo2       |               |                          v
| Jmp returnTarget  |               v               +---------------------+
+-------------------+    +---------------------+    | tb = LdStk          |
           |             | tb = LdStk          |    | LeaveInlineFrame    |
           v             | InlineSuspend       |    | StStk tb            |
+-------------------+    | StStk tb            |    +---------------------+
| DecRef Locals     |    | tc = LdStk          |               |
| DecRef This       |    | te = LdWhState tc   |               v
| tr = LdStk        |    | JmpZero te          |--------->*Side Exit*
| LeaveInlineFrame  |    +---------------------+
| StStk tr          |               |
| CreateSSWH (*)    |               |
+-------------------+               v
           |             +---------------------+
           |             | td = CreateAFWH tc  |
           v             | SuspendHook         |
          ...            | RetCtrl td          |
                         +---------------------+
*/

#include "hphp/runtime/vm/jit/irgen-inlining.h"

#include "hphp/runtime/vm/jit/mutation.h"

#include "hphp/runtime/vm/jit/irgen.h"
#include "hphp/runtime/vm/jit/irgen-call.h"
#include "hphp/runtime/vm/jit/irgen-control.h"
#include "hphp/runtime/vm/jit/irgen-exit.h"
#include "hphp/runtime/vm/jit/irgen-internal.h"
#include "hphp/runtime/vm/jit/irgen-sprop-global.h"

#include "hphp/runtime/vm/resumable.h"
#include "hphp/runtime/vm/unwind.h"
#include "hphp/runtime/vm/jit/inlining-decider.h"
#include "hphp/runtime/vm/jit/mcgen-translate.h"
#include "hphp/runtime/vm/jit/translate-region.h"

namespace HPHP::jit::irgen {

TRACE_SET_MOD(hhir)

RegionAndLazyUnit::RegionAndLazyUnit(
    SrcKey callerSk,
    RegionDescPtr region
  ) : m_callerSk(callerSk)
    , m_region(std::move(region)) {}

IRUnit* RegionAndLazyUnit::unit() const {
    if (m_unit) return m_unit.get();
    always_assert(m_region);
    TransContext ctx {
      TransIDSet{},
      0,  // optIndex
      TransKind::Optimize,
      m_callerSk,
      m_region.get(),
      m_callerSk.packageInfo(),
      PrologueID(),
    };
    tracing::Block _{"compute-inline-cost", [&] { return traceProps(ctx); }};
    rqtrace::DisableTracing notrace;
    auto const unbumper = mcgen::unbumpFunctions();
    m_unit = irGenInlineRegion(ctx, *m_region);
    return m_unit.get();
}

bool isInlining(const IRGS& env) {
  return !env.inlineState.frames.empty();
}

uint16_t inlineDepth(const IRGS& env) {
  return env.inlineState.frames.size();
}

SSATmp* genCalleeFP(IRGS& env, const Func* callee, int argc) {
  auto sk = curSrcKey(env);
  if (!sk.prologue()) sk.advance(curFunc(env));
  assertx(env.lastDefFramePtr || sk.prologue());

  if (env.irb->inUnreachableState()) return cns(env, TBottom);

  auto const spOff = sk.prologue()
    ? IRSPRelOffset { 0 }
    : spOffBCFromIRSP(env) + argc;

  auto const def = env.unit.gen(
    DefCalleeFP,
    env.irb->nextBCContext(),
    DefCalleeFPData{
      spOff,                                                   // spOff
      callee,
      static_cast<uint32_t>(inlineDepth(env) + 1),
      sk,
      spOffBCFromIRSP(env) + argc - callee->numSlotsInFrame(), // calleeSBOff
      spOffBCFromStackBase(env) - argc - kNumActRecCells + 1,  // returnSPOff
      0   // cost
    },
    sp(env),
    fp(env)
  );

  if (curSrcKey(env).prologue()) {
    env.irb->optimizeInst(def, IRBuilder::CloneFlag::No, nullptr);
    return def->dst();
  }

  auto const block = env.lastDefFramePtr->block();
  block->insert(++block->iteratorTo(env.lastDefFramePtr), def);
  env.lastDefFramePtr = def;
  return def->dst();
}

void beginInlining(IRGS& env,
                   SrcKey entry,
                   SSATmp* ctx,
                   Offset asyncEagerOffset,
                   int cost,
                   SSATmp* calleeFP) {
  assertx(entry.funcEntry());
  auto const callee = entry.func();
  auto frame = InlineFrame {
    env.bcState,
    irgen::defBlock(env),  // returnTarget
    irgen::defBlock(env),  // suspendTarget
    irgen::defBlock(env, Block::Hint::Unused),  // sideExitTarget
    irgen::defBlock(env, Block::Hint::Unused),  // endCatchTarget
    irgen::defBlock(env, Block::Hint::Unused),  // endCatchLocalsDecRefdTarget
    asyncEagerOffset,
    env.inlineState.cost
  };

  FTRACE(1, "[[[ begin inlining: {}\n", callee->fullName()->data());

  auto const numTotalInputs = callee->numFuncEntryInputs();

  jit::vector<SSATmp*> inputs{numTotalInputs};
  for (auto i = 0; i < numTotalInputs; ++i) {
    inputs[numTotalInputs - i - 1] = popCU(env);
  }

  while (entry.trivialDVFuncEntry()) {
    auto const param = entry.numEntryArgs();
    assertx(param < numTotalInputs);
    auto const dv = callee->params()[param].defaultValue;
    inputs[param] = cns(env, dv);
    entry = SrcKey{callee, param + 1, SrcKey::FuncEntryTag {}};
  }

  updateMarker(env);

  // NB: Now that we've popped the callee's arguments off the stack
  // and thus modified the caller's frame state, we're committed to
  // inlining. If we bail out from now on, the caller's frame state
  // will be as if the arguments don't exist on the stack (even though
  // they do).
  auto const extra = calleeFP->inst()->extra<DefCalleeFP>();
  extra->cost = cost;

  always_assert(extra->spOffset == spOffBCFromIRSP(env));
  always_assert(extra->sbOffset == extra->spOffset - callee->numSlotsInFrame());

  // Make the new FramePtr live (marking the caller stack below the frame as
  // killed).
  gen(env, EnterInlineFrame, calleeFP);

  env.inlineState.frames.emplace_back(frame);
  env.inlineState.cost += cost;
  env.inlineState.stackDepth += callee->maxStackCells();
  env.bcState = entry;

  // We have entered a new frame.
  updateMarker(env);
  env.irb->exceptionStackBoundary();

  if (!(ctx->type() <= TNullptr)) gen(env, StFrameCtx, fp(env), ctx);

  for (auto i = 0; i < numTotalInputs; ++i) {
    stLocRaw(env, i, calleeFP, inputs[i]);
  }

  assertx(entry.hasThis() == callee->hasThisInBody());
  assertx(
    ctx->isA(TBottom) ||
    (ctx->isA(TNullptr) && !callee->cls()) ||
    (ctx->isA(TCls) && callee->cls() && callee->isStatic()) ||
    (ctx->isA(TObj) && callee->cls() && !callee->isStatic()) ||
    (ctx->isA(TObj) && callee->isClosureBody())
  );
}

void conjureBeginInlining(IRGS& env,
                          SrcKey entry,
                          Type thisType,
                          const std::vector<Type>& inputs) {
  assertx(entry.funcEntry());
  auto const callee = entry.func();
  auto const profCount = curProfCount(env);

  auto conjure = [&](Type t) {
    return t.admitsSingleVal() ? cns(env, t) : gen(env, Conjure, t);
  };

  // thisType is the context type inside the closure, but beginInlining()'s ctx
  // is a context given to the prologue.
  always_assert(thisType != TBottom);
  auto const ctx = callee->isClosureBody()
    ? conjure(Type::ExactObj(callee->implCls()))
    : conjure(thisType);

  // Push $this object to the lockable position.
  if (callee->cls() && callee->cls()->getCtor() == callee) {
    push(env, ctx);
  }

  // Push space for out parameters
  for (auto i = 0; i < callee->numInOutParams(); i++) {
    push(env, cns(env, TUninit));
  }

  allocActRec(env);
  auto const fp = genCalleeFP(env, callee, 0);

  for (auto const inputType : inputs) {
    push(env, conjure(inputType));
  }

  // beginInlining() assumes synced state.
  updateMarker(env);
  env.irb->exceptionStackBoundary();

  beginInlining(env, entry, ctx, kInvalidOffset /* asyncEagerOffset */,
                9 /* cost */, fp);
  // Set the prof count on the return block.
  // FIXME: Why is this needed? Should it be set for other blocks as well, e.g.
  // suspendRetBlock? Is something similar needed for real translations?
  env.inlineState.frames.back().returnTarget->setProfCount(profCount);
}

namespace {
struct InlineFrameSave {
  SrcKey bcState;
  InlineFrame frame;
};

InlineFrameSave popInlineFrame(IRGS& env) {
  always_assert(env.inlineState.frames.size() > 0);

  InlineFrameSave save { env.bcState, env.inlineState.frames.back() };
  env.inlineState.frames.pop_back();

  // Pop the inlined frame in our IRGS.  Be careful between here and the
  // updateMarker() below, where the caller state isn't entirely set up.
  env.inlineState.cost = save.frame.savedCost;
  env.inlineState.stackDepth -= save.bcState.func()->maxStackCells();
  env.bcState = save.frame.callerSk;

  updateMarker(env);
  env.irb->exceptionStackBoundary();

  return save;
}

void pushInlineFrame(IRGS& env, const InlineFrameSave& save) {
  // No need to update cost, as we are not going to recursively inline anything
  // during a single Jmp opcode we are restoring the state for.
  env.inlineState.stackDepth += save.bcState.func()->maxStackCells();
  env.bcState = save.bcState;

  env.inlineState.frames.emplace_back(save.frame);

  updateMarker(env);
  env.irb->exceptionStackBoundary();
}

InlineFrameSave implInlineReturn(IRGS& env) {
  assertx(resumeMode(env) == ResumeMode::None);

  // Return to the caller function.
  gen(env, LeaveInlineFrame, fp(env));

  return popInlineFrame(env);
}

void freeInlinedFrameLocals(IRGS& env, const RegionDesc& calleeRegion) {
  // The IR instructions should be associated with one of the return bytecodes;
  // all predecessors of this block should be valid options. Choose the hottest
  // predecessor in order to get the most-likely DecRefProfiles.
  auto const curBlock = env.irb->curBlock();
  always_assert(curBlock && !curBlock->preds().empty());
  auto best = curBlock->preds().front().inst();
  for (auto const& pred : curBlock->preds()) {
    if (pred.inst()->block()->profCount() > best->block()->profCount()) {
      best = pred.inst();
    }
  }
  auto const bcContext = best->bcctx();
  env.bcState = bcContext.marker.sk();
  env.irb->setCurMarker(bcContext.marker);

  // At this point, env.profTransIDs and env.region are already set with the
  // caller's information.  We temporarily reset both of these with the callee's
  // information, so that the HHIR instructions emitted for the RetC have their
  // markers associated with the callee.  This is necessary to successfully look
  // up any profile data associated with them.
  auto const callerProfTransIDs = env.profTransIDs;
  auto const callerRegion       = env.region;
  SCOPE_EXIT{
    env.profTransIDs = callerProfTransIDs;
    env.region       = callerRegion;
  };
  auto const& calleeTransIDs = bcContext.marker.profTransIDs();
  env.profTransIDs = calleeTransIDs;
  env.region = &calleeRegion;
  updateMarker(env);
  env.irb->resetCurIROff(bcContext.iroff + 1);

  decRefLocalsInline(env);
  decRefThis(env);
}

void implReturnBlock(IRGS& env, const RegionDesc& calleeRegion) {
  auto const frame = env.inlineState.frames.back();
  auto const didStart = env.irb->startBlock(frame.returnTarget, false);
  always_assert(didStart);

  freeInlinedFrameLocals(env, calleeRegion);

  auto const callee = curFunc(env);

  auto const nret = callee->numInOutParams() + 1;
  if (nret > 1 && callee->isCPPBuiltin()) {
    auto const ret = pop(env, DataTypeGeneric);
    implInlineReturn(env);
    for (int32_t idx = 0; idx < nret - 1; ++idx) {
      auto const off = offsetFromIRSP(env, BCSPRelOffset{idx});
      auto const type = callOutType(callee, idx, false /* mayIntercept */);
      gen(env, AssertStk, type, IRSPRelOffsetData{off}, sp(env));
    }
    auto const type = callReturnType(callee, false /* mayIntercept */);
    push(env, gen(env, AssertType, type, ret));
    return;
  }

  jit::vector<SSATmp*> retVals{nret, nullptr};
  for (auto& v : retVals) v = pop(env, DataTypeGeneric);

  implInlineReturn(env);

  // Pop the NullUninit values from the stack.
  for (uint32_t idx = 0; idx < nret - 1; ++idx) pop(env);

  if (!callee->isAsyncFunction()) {
    // Non-async function. Just push the result on the stack.
    if (nret > 1) {
      for (int32_t idx = nret - 2; idx >= 0; --idx) {
        auto const val = retVals[idx];
        auto const type = callOutType(callee, idx, false /* mayIntercept */);
        push(env, gen(env, AssertType, type, val));
      }
    }
    auto const type = callReturnType(callee, false /* mayIntercept */);
    push(env, gen(env, AssertType, type, retVals.back()));
    return;
  }

  assertx(nret == 1);
  auto const type = awaitedCallReturnType(callee, false /* mayIntercept */);
  auto const retVal = gen(env, AssertType, type, retVals.back());
  if (frame.asyncEagerOffset == kInvalidOffset) {
    // Async eager return was not requested. Box the returned value and
    // continue execution at the next opcode.
    push(env, gen(env, CreateSSWH, retVal));
  } else {
    // Async eager return was requested. Continue execution at the async eager
    // offset with the returned value.
    push(env, retVal);
    jmpImpl(env, bcOff(env) + frame.asyncEagerOffset);
  }
}

bool implSuspendBlock(IRGS& env, bool exitOnAwait) {
  auto const frame = env.inlineState.frames.back();
  // Start a new IR block to hold the remainder of this block.
  auto const didStart = env.irb->startBlock(frame.suspendTarget, false);
  if (!didStart) return false;

  // We strive to inline regions which will mostly eagerly terminate.
  if (exitOnAwait) hint(env, Block::Hint::Unlikely);

  assertx(curFunc(env)->isAsyncFunction());
  auto const block = frame.suspendTarget;
  auto const label = env.unit.defLabel(1, block, env.irb->nextBCContext());
  auto const wh = label->dst(0);
  retypeDests(label, &env.unit);

  auto const inlineFrame = implInlineReturn(env);
  SCOPE_EXIT { if (exitOnAwait) pushInlineFrame(env, inlineFrame); };

  push(env, wh);
  if (exitOnAwait) {
    if (frame.asyncEagerOffset == kInvalidOffset) {
      gen(env, Jmp, makeExit(env, nextSrcKey(env)));
    } else {
      jmpImpl(env, nextSrcKey(env));
    }
  }
  return true;
}

void implSideExitBlock(IRGS& env) {
  auto const frame = env.inlineState.frames.back();
  auto const didStart = env.irb->startBlock(frame.sideExitTarget, false);
  if (!didStart) return;

  hint(env, Block::Hint::Unlikely);
  auto const calleeFP = fp(env);

  auto const block = frame.sideExitTarget;
  auto const label = env.unit.defLabel(1, block, env.irb->nextBCContext());
  auto const targetAddr = label->dst(0);
  retypeDests(label, &env.unit);

  env.irb->fs().endInliningForSideExit();
  auto const inlineFrame = popInlineFrame(env);
  SCOPE_EXIT { pushInlineFrame(env, inlineFrame); };

  auto const iseData = InlineSideExitData {
    inlineFrame.bcState.func(),
    isInlining(env) ? env.inlineState.frames[0].callerSk.offset() : bcOff(env)
  };
  auto const retVal =
    gen(env, InlineSideExit, iseData, sp(env), calleeFP, fp(env), targetAddr);
  push(env, retVal);
  gen(env, Jmp, makeExit(env, nextSrcKey(env)));
}

void implEndCatchBlock(IRGS& env, const RegionDesc& calleeRegion) {
  auto const frame = env.inlineState.frames.back();

  auto const didStart = env.irb->startBlock(frame.endCatchTarget, false);
  if (didStart) {
    hint(env, Block::Hint::Unused);
    auto const block = frame.endCatchTarget;
    auto const label = env.unit.defLabel(1, block, env.irb->nextBCContext());
    auto const exc = label->dst(0);
    retypeDests(label, &env.unit);
    freeInlinedFrameLocals(env, calleeRegion);
    gen(env, Jmp, frame.endCatchLocalsDecRefdTarget, exc);
  }

  auto const didStartLocalsDecRefd =
    env.irb->startBlock(frame.endCatchLocalsDecRefdTarget, false);
  if (!didStartLocalsDecRefd) return;

  hint(env, Block::Hint::Unused);
  auto const block = frame.endCatchLocalsDecRefdTarget;
  auto const label = env.unit.defLabel(1, block, env.irb->nextBCContext());
  auto const exc = label->dst(0);
  retypeDests(label, &env.unit);

  // If this async function was called without an associated await,
  // the exception needs to be wrapped into an Awaitable.
  auto const wrapToAwaitable =
    curFunc(env)->isAsync() && frame.asyncEagerOffset == kInvalidOffset;

  auto const inlineFrame = implInlineReturn(env);
  SCOPE_EXIT { pushInlineFrame(env, inlineFrame); };

  emitLockObjOnFrameUnwind(env, curSrcKey(env).pc());

  auto const handleException = [&] {
    // vmspOffset is unknown at this point due to multiple BeginCatches
    emitHandleException(
      env, EndCatchData::CatchMode::UnwindOnly, exc, std::nullopt);
  };

  if (wrapToAwaitable) {
    cond(
      env,
      [&](Block* taken) {
        return gen(env, CheckNonNull, taken, exc);
      },
      [&](SSATmp* exception) {
        // Wrap Hack exceptions into Awaitables and continue at the next opcode.
        push(env, gen(env, CreateFSWH, exception));
        gen(env, Jmp, makeExit(env, nextSrcKey(env)));
        return nullptr;
      },
      [&] {
        // C++ exceptions don't get wrapped into an Awaitable.
        handleException();
        return nullptr;
      }
    );
    return;
  }

  handleException();
}

////////////////////////////////////////////////////////////////////////////////
}

bool endInlining(IRGS& env, const RegionDesc& calleeRegion) {
  auto const frame = env.inlineState.frames.back();

  implSideExitBlock(env);

  implEndCatchBlock(env, calleeRegion);

  if (env.irb->canStartBlock(frame.returnTarget)) {
    implSuspendBlock(env, true);
  } else {
    return implSuspendBlock(env, false);
  }

  implReturnBlock(env, calleeRegion);

  FTRACE(1, "]]] end inlining: {}\n", curFunc(env)->fullName()->data());
  return true;
}

bool conjureEndInlining(IRGS& env, const RegionDesc& calleeRegion,
                        bool builtin) {
  auto const callee = curFunc(env);
  if (!endInlining(env, calleeRegion)) return false;
  auto spOff = spOffBCFromIRSP(env);
  gen(env, EndBlock, EndBlockData{spOff, callee, ASSERT_REASON.reason});
  return true;
}

void retFromInlined(IRGS& env) {
  gen(env, Jmp, env.inlineState.frames.back().returnTarget);
}

void suspendFromInlined(IRGS& env, SSATmp* waitHandle) {
  gen(env, Jmp, env.inlineState.frames.back().suspendTarget, waitHandle);
}

void sideExitFromInlined(IRGS& env, SrcKey target) {
  assertx(isInlining(env));

  if (target.funcEntry()) {
    // FIXME: Func entries may contain guards that might fail. Ideally we would
    // CallFuncEntry in these situations, but CallFuncEntry accepts arguments on
    // the stack and we already converted them to the locals.
    spillInlinedFrames(env);

    auto const invSP = spOffBCFromStackBase(env);
    auto const irSP = spOffBCFromIRSP(env);
    gen(
      env,
      ReqBindJmp,
      ReqBindJmpData { target, invSP, irSP, target.funcEntry() },
      sp(env),
      fp(env)
    );
    return;
  }

  auto const invSP = spOffBCFromStackBase(env);
  auto const bindData = LdBindAddrData { target, invSP };
  auto const targetAddr = gen(env, LdBindAddr, bindData);
  sideExitFromInlined(env, targetAddr);
}

void sideExitFromInlined(IRGS& env, SSATmp* target) {
  auto const invSP = spOffBCFromStackBase(env);
  auto const sr = StackRange {
    spOffBCFromIRSP(env),
    safe_cast<uint32_t>(invSP - spOffEmpty(env))
  };
  gen(env, InlineSideExitSyncStack, sr, sp(env));
  updateMarker(env);
  env.irb->exceptionStackBoundary();

  gen(env, Jmp, env.inlineState.frames.back().sideExitTarget, target);
}

void endCatchFromInlined(IRGS& env, EndCatchData::CatchMode mode, SSATmp* exc) {
  assertx(isInlining(env));
  assertx(mode == EndCatchData::CatchMode::UnwindOnly ||
          mode == EndCatchData::CatchMode::LocalsDecRefd);
  assertx(mode == EndCatchData::CatchMode::LocalsDecRefd ||
          findExceptionHandler(curFunc(env), bcOff(env)) == kInvalidOffset ||
          exc->type() <= TNullptr);
  assertx(fp(env) != env.irb->fs().fixupFP());

  // Clear the evaluation stack and jump to the shared EndCatch handler.
  int locId = 0;
  while (spOffBCFromStackBase(env) > spOffEmpty(env)) {
    popDecRef(env, static_cast<DecRefProfileId>(locId++));
  }
  auto const target = mode == EndCatchData::CatchMode::UnwindOnly
    ? env.inlineState.frames.back().endCatchTarget
    : env.inlineState.frames.back().endCatchLocalsDecRefdTarget;
  gen(env, Jmp, target, exc);
}

bool spillInlinedFrames(IRGS& env) {
  assertx(inlineDepth(env) == env.irb->fs().inlineDepth());

  // Nothing to spill.
  if (!isInlining(env)) return false;

  auto const fixupFP = env.irb->fs().fixupFP();
  bool spilled = false;
  for (size_t depth = 0; depth < env.irb->fs().inlineDepth(); depth++) {
    auto const parentFP = env.irb->fs()[depth].fp();
    if (parentFP == fixupFP) spilled = true;
    if (spilled) {
      auto const fp = env.irb->fs()[depth + 1].fp();

      // Inline return stub doesn't support async eager return.
      StFrameMetaData meta;
      meta.callBCOff = fp->inst()->marker().sk().offset();
      meta.isInlined = true;
      meta.asyncEagerReturn = false;
      gen(env, StFrameMeta, meta, fp);

      auto const func = env.irb->fs()[depth + 1].curFunc;
      gen(env, StFrameFunc, FuncData { func }, fp);

      gen(env, InlineCall, fp, parentFP);
      updateMarker(env);
    }
  }
  return spilled;
}

//////////////////////////////////////////////////////////////////////

}
